{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the data\n",
    "baseline = pd.read_csv('allfeatures_norm_Baseline.csv')\n",
    "# add a new column to display target variable\n",
    "baseline['target'] = 1\n",
    "followup = pd.read_csv('allfeatures_norm_Controls.csv')\n",
    "# add a new column to display target variable\n",
    "followup['target'] = 0\n",
    "\n",
    "# concatenate the two dataframes\n",
    "all_data = pd.concat([baseline, followup], ignore_index=True)\n",
    "\n",
    "# subset data where label is 1\n",
    "cistern_data = all_data[all_data['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "#warnings.simplefilter(action='ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns with datatype object\n",
    "cistern_data = cistern_data.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cistern_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # split data into train and test\n",
    "\n",
    "# X = cistern_data.drop(['label'], axis=1)\n",
    "# y = cistern_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature selection using correlation\n",
    "\n",
    "# # get correlation matrix\n",
    "# corr_matrix = X.corr().abs()\n",
    "\n",
    "# # get upper triangle of correlation matrix\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# # get columns with correlation greater than 0.95\n",
    "\n",
    "# to_drop_ = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# # # drop columns with correlation greater than 0.95\n",
    "# # cistern_data = cistern_data.drop(cistern_data[to_drop], axis=1)\n",
    "\n",
    "# # drop columns with correlation less than 0.1\n",
    "\n",
    "# # to_drop = [column for column in upper.columns if any(upper[column] < 0.1)]\n",
    "\n",
    "# to_drop = corr_matrix[corr_matrix['target'] < 0.1].index.tolist()\n",
    "# # drop columns with correlation less than 0.1\n",
    "# X = X.drop(X[to_drop+to_drop_], axis=1)\n",
    "\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lightgbm to select features\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(cistern_data.drop('target', axis=1), cistern_data['target'], test_size=0.2, random_state=42,shuffle=True, stratify=cistern_data['target'])\n",
    "\n",
    "# create lgb dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# set parameters\n",
    "param = {'num_leaves': 31, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "\n",
    "# train the model\n",
    "num_round = 100\n",
    "bst = lgb.train(param, train_data, num_round)\n",
    "\n",
    "# plot feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "lgb.plot_importance(bst, figsize=(12, 6))\n",
    "plt.show()\n",
    "\n",
    "# select features with importance > 0.01\n",
    "selected_features = []\n",
    "\n",
    "for i in range(len(bst.feature_importance())):\n",
    "    if bst.feature_importance()[i] > 0.01:\n",
    "        selected_features.append(bst.feature_name()[i])\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(bst.feature_importance())[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bst.feature_importance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "colors = ['orange', 'green', 'blue', 'cyan', 'magenta']\n",
    "\n",
    "# Set up K-Fold cross-validation\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "X = np.array(cistern_data[selected_features])\n",
    "y = np.array(cistern_data['target'])\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "conf_matrices = []\n",
    "roc = []\n",
    "legend_label = []\n",
    "fprl = []\n",
    "tprl = []\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.0])\n",
    "plt.ylim([-0.1, 1.0])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Create and fit the model\n",
    "    model = lgb.LGBMClassifier(learning_rate=0.01, n_estimators=1000, num_leaves=31, objective='binary', metric='accuracy ')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate and store metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    conf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    roc.append(roc_auc_score(y_pred, y_test))\n",
    "\n",
    "    feature_imp = pd.DataFrame(sorted(zip(model.feature_importances_, selected_features)), columns=['Value', 'Feature'])\n",
    "\n",
    "    # show top 20 features\n",
    "\n",
    "    # plt.figure(figsize=(20, 10))\n",
    "    # sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[:20])\n",
    "    # plt.title('LightGBM Features (avg over folds)')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # plot ROC curve\n",
    "    probs = model.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    print(preds)\n",
    "    print(y_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, colors[fold])\n",
    "    # add legend for each fold with AUC score and color of line\n",
    "    legend_label.append('Fold {} (AUC = {:.2f})'.format(fold, roc_auc))\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "    print(legend_label)\n",
    "\n",
    "plt.legend(['Baseline (AUC = 0.50)'] + legend_label, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "\n",
    "# Output average results\n",
    "print(\"Average Accuracy: {:.2f}%\".format(avg_accuracy * 100))\n",
    "print(\"Average F1 Score: {:.2f}%\".format(avg_f1_score * 100))\n",
    "\n",
    "# Aggregate confusion matrices\n",
    "total_conf_matrix = np.sum(conf_matrices, axis=0)\n",
    "\n",
    "# Output the aggregated confusion matrix\n",
    "print(\"Aggregated Confusion Matrix:\")\n",
    "print(total_conf_matrix)\n",
    "\n",
    "# Output the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Average ROC\n",
    "avg_roc = np.mean(roc)\n",
    "print(\"Average ROC: {:.2f}%\".format(avg_roc * 100))\n",
    "\n",
    "# create heartmap of confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(total_conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Aggregated Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the lightgbm model\n",
    "clf = lgb.LGBMClassifier(learning_rate=0.01, n_estimators=1000, num_leaves=31, objective='binary', metric='accuracy', importance_type='gain')\n",
    "clf.fit(cistern_data[selected_features], cistern_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "\n",
    "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_, selected_features)), columns=['Value', 'Feature'])\n",
    "\n",
    "# show top 20 features\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[:20])\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import joblib\n",
    "\n",
    "xgb_exp = shap.TreeExplainer(clf, feature_perturbation='tree_path_dependent', feature_names=selected_features)\n",
    "shap_values = xgb_exp.shap_values(cistern_data[selected_features])\n",
    "shap.summary_plot(shap_values, cistern_data[selected_features], feature_names=selected_features)\n",
    "'''shap.plots.beeswarm(shap_values = xgb_exp)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHAP values\n",
    "explainer = shap.Explainer(clf, cistern_data[selected_features])\n",
    "shap_values = explainer(cistern_data[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values, max_display=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHAP values\n",
    "explainer = shap.Explainer(clf, cistern_data[selected_features])\n",
    "shap_values = explainer(cistern_data[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.violin(\n",
    "    shap_values, features=cistern_data[selected_features], feature_names=selected_features, plot_type=\"layered_violin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
